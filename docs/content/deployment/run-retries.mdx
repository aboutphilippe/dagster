---
title: Run retries | Dagster
description: Automatically retry Dagster runs
---

# Run Retries

If you configure retries at the run level, a new run will be kicked off whenever a run fails for any reason. Compared to [Op retries](/concepts/ops-jobs-graphs/op-retries), the maximum retry limit for run retries applies to the whole run instead of each individual Op. Run retries also handle the case where a run worker crashes or is unexpectedly terminated.

## Configuration

How to configure a default maximum number of retries for all runs in your Dagster deployment depends on whether you're using Dagster Cloud or Dagster Open Source:

- **Dagster Cloud**: Use the \[Dagster Cloud UI or the dagster-cloud CLI]\[cloud-deployment-settings]
- **Dagster Open Source**: Use your instance's `dagster.yaml`

For example, the following will set a default maximum number of retries of 3 for all runs:

```yaml file=/deploying/dagster_instance/dagster.yaml startafter=start_run_retries endbefore=end_run_retries
run_retries:
  max_retries: 3
```

In both Dagster Cloud and Dagster Open Source, you can also configure retries using tags either on Job definitions or in the Dagster UI [Launchpad](/concepts/webserver/ui#launchpad-tab).

```python file=/deploying/job_retries.py
from dagster import job


@job(tags={"dagster/max_retries": 3})
def sample_job():
    pass


@job(tags={"dagster/max_retries": 3, "dagster/retry_strategy": "ALL_STEPS"})
def other_sample_sample_job():
    pass
```

### Retry Strategy

The `dagster/retry_strategy` tag controls which Ops the retry will run.

By default, retries will re-execute from failure (tag value `FROM_FAILURE`). This means that any successful Ops will be skipped, but their output will be used for downstream Ops. If the `dagster/retry_strategy` tag is set to `ALL_STEPS`, all the Ops will run again.

**Note:** `FROM_FAILURE` requires an IOManager that can access outputs from other runs. For example, on Kubernetes the [s3\_pickle_io_manager](/\_apidocs/libraries/dagster-aws#dagster_aws.s3.s3\_pickle_io_manager) would work but the [`FilesytemIOManager`](https://docs.dagster.io/\_apidocs/io-managers#dagster.FilesytemIOManager) would not, since the new run is in a new Kubernetes Job with a separate filesystem.

### Combining op retries and run retries

By default, if a run fails due to an op failure and both op retries and run retries are enabled, the overlapping retries might cause the op to be retried more times than desired, since the op retry count will reset for each retried run.

To prevent this from happening, you can configure run retries to only retry when the failure is due to a reason other than an op failure (for example, a crash or an unexpected termination of the run worker). This is controlled by the `run_retries.retry_on_asset_or_op_failure` setting, which defaults to true but can be overridden to false.

For example, the following configures run retries so that they ignore runs that failed due to a step failure:

```yaml
run_retries:
  max_retries: 3
  retry_on_asset_or_op_failure: false
```

**Note:** Setting `retry_on_asset_or_op_failure` for false will only change retry behavior for runs on dagster version 1.6.7 or greater.
